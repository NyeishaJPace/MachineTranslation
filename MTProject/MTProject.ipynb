{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Machine Translation Project 2025\n",
    "#### Tech Stack: Python, Hugging Face MarianMT, NLTK/ChatterBot/GPT-based chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installed packages for this project\n",
    "\n",
    "Packages Installed: transformers, torch, nltk, chatterbot, chatterbot_corpus, spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MarianMT model is loaded for translating from source to the target language\n",
    "def load_translation_model(src_lang=\"fr\", tgt_lang=\"en\"):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "    \n",
    "# The text is translated using the MarianMT model\n",
    "def translate(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated: Les clowns s'étaient emparés.Et oui, ils étaient littéralement des clowns.Plus de 100 étaient apparus d'un petit bug VW qui avait été conduit jusqu'à la banque.Maintenant ils étaient tous à l'intérieur et l'avaient pris.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_en_fr, tokenizer_en_fr = load_translation_model(\"en\", \"fr\")  # English → French\n",
    "model_fr_en, tokenizer_fr_en = load_translation_model(\"fr\", \"en\")  # French → English\n",
    "\n",
    "text = \"The clowns had taken over. And yes, they were literally clowns.\"  \\\n",
    "\"Over 100 had appeared out of a small VW bug that had been driven up to the bank.\" \\\n",
    "\"Now they were all inside and had taken it over.\"\n",
    "translated_text = translate(text, model_en_fr, tokenizer_en_fr)\n",
    "print(f\"Translated: {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the AI chatbot by utilizing the Chatterbot library\n",
    "import spacy\n",
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"SpaCy model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChatterBot Corpus Trainer: 26it [00:03,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Je suis interesse par beaucoup de choses. Nous pouvons parler de n'importe quoi!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chatbot = ChatBot('MultilingualBot')\n",
    "\n",
    "trainer = ChatterBotCorpusTrainer(chatbot)\n",
    "  \n",
    "# Train the bot with multiple corpus\n",
    "trainer.train(\"chatterbot.corpus.english.greetings\",\n",
    "              \"chatterbot.corpus.english\",\n",
    "              \"chatterbot.corpus.french\",\n",
    "              \"chatterbot.corpus.english.conversations\" )\n",
    "  \n",
    "def get_chatbot_response(user_input):\n",
    "    return chatbot.get_response(user_input).text\n",
    "\n",
    " \n",
    "user_input = \"Quels sont tes centres d'interets\"\n",
    "response = get_chatbot_response(user_input)\n",
    "print(f\"Chatbot: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Je vais bien.\n"
     ]
    }
   ],
   "source": [
    "# Connect chatbot with translation\n",
    "\n",
    "def multilingual_chatbot(user_input, user_lang=\"fr\"):\n",
    "    model_user_to_en, tokenizer_user_to_en = load_translation_model(user_lang, \"en\")\n",
    "    translated_input = translate(user_input, model_user_to_en, tokenizer_user_to_en)\n",
    "    \n",
    "    # Get chatbot response in English\n",
    "    chatbot_response = get_chatbot_response(translated_input)\n",
    "    \n",
    "    # Translate chatbot response back to user language\n",
    "    model_en_to_user, tokenizer_en_to_user = load_translation_model(\"en\", user_lang)\n",
    "    final_response = translate(chatbot_response, model_en_to_user, tokenizer_en_to_user)\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "user_message = \"Bonjour! Comment ça va?\"  # French input\n",
    "response = multilingual_chatbot(user_message, user_lang=\"fr\")\n",
    "print(f\"Chatbot: {response}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
